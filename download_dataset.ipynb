{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597dbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/spatialrgpt_finetune/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 201 files: 100%|██████████| 201/201 [00:03<00:00, 50.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/root/SpatialRGPT/PhysicalAI-Spatial-Intelligence-Warehouse'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download train_sample\n",
    "from huggingface_hub import snapshot_download, login\n",
    "import os\n",
    "\n",
    "login('')\n",
    "\n",
    "os.makedirs(\"PhysicalAI-Spatial-Intelligence-Warehouse\", exist_ok=True)\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"nvidia/PhysicalAI-Spatial-Intelligence-Warehouse\",\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=\"PhysicalAI-Spatial-Intelligence-Warehouse\",\n",
    "    allow_patterns=\"train_sample/*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b7f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move train_sample.json to like data folder stuture\n",
    "!cp PhysicalAI-Spatial-Intelligence-Warehouse/train_sample/train_sample.json PhysicalAI-Spatial-Intelligence-Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a577ffed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git: 'lfs' is not a git command. See 'git --help'.\n",
      "\n",
      "The most similar command is\n",
      "\tlog\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/spatialrgpt_finetune/lib/python3.10/site-packages/huggingface_hub/commands/download.py:139: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
      "  warnings.warn(\n",
      "Fetching 20 files: 100%|██████████████████████| 20/20 [00:00<00:00, 2021.06it/s]\n",
      "/root/SpatialRGPT/checkpoints/SpatialRGPT-VILA1.5-8B\n"
     ]
    }
   ],
   "source": [
    "# download pretrain mdoel\n",
    "!git lfs install\n",
    "!huggingface-cli download a8cheng/SpatialRGPT-VILA1.5-8B \\\n",
    "    --local-dir checkpoints/SpatialRGPT-VILA1.5-8B \\\n",
    "    --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfd5961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/spatialrgpt_finetune/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-04 10:04:41,827] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "model_name_inferred: SpatialRGPT-VILA1.5-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:16<00:00,  4.05s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming region extractor from:  checkpoints/SpatialRGPT-VILA1.5-8B/region_extractor\n",
      "SpatialRGPT model loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load model from HuggingFace or Dowloaded Checkpoint\n",
    "from llava.mm_utils import get_model_name_from_path\n",
    "from llava.model.builder import load_pretrained_model # To get tokenizer and image_processor\n",
    "\n",
    "args_model_path = \"checkpoints/SpatialRGPT-VILA1.5-8B\"\n",
    "# args_model_path = \"checkpoints/SpatialRGPT-VILA1.5-8B\"\n",
    "args_model_base = None\n",
    "args_conv_mode = \"llava_v1\"\n",
    "\n",
    "model_name_inferred = get_model_name_from_path(args_model_path)\n",
    "print(f\"model_name_inferred: {model_name_inferred}\")\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    model_path = args_model_path,\n",
    "    model_name = model_name_inferred,\n",
    "    model_base = args_model_base,\n",
    "    load_8bit=False,\n",
    "    load_4bit=False,\n",
    "    device_map='auto',\n",
    "    device='cuda'\n",
    ")\n",
    "print(\"SpatialRGPT model loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a577e43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PhysicalAI-Spatial-Intelligence-Warehouse/train.json'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download file of dataset from huggingface\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "hf_hub_download(\n",
    "    repo_id=\"nvidia/PhysicalAI-Spatial-Intelligence-Warehouse\",\n",
    "    repo_type=\"dataset\",\n",
    "    filename=\"train.json\",\n",
    "    local_dir=\"PhysicalAI-Spatial-Intelligence-Warehouse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127ed834-e714-4410-9191-ca4ff6478c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 499083\n"
     ]
    }
   ],
   "source": [
    "# Read \n",
    "# Read train.json\n",
    "import json\n",
    "filename = \"PhysicalAI-Spatial-Intelligence-Warehouse/train.json\"\n",
    "with open(filename, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(f\"Number of samples: {len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d27652-24da-4dc1-882f-453639f3c770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'image', 'conversations', 'rle', 'category', 'normalized_answer', 'freeform_answer'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3c4b09e-5f07-430a-b4ac-0059e7fee48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "idx = random.randint(0, len(train_data))\n",
    "len(train_data[idx]['conversations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42f799f7-7122-4297-8284-7469374db05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_single_turn_conversation(samples):\n",
    "    num_turns = [len(sample['conversations'])/2 for sample in samples]\n",
    "    return sum(num_turns) == float(len(samples))\n",
    "\n",
    "samples = random.sample(train_data, 1000)\n",
    "is_single_turn_conversation(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "22a87b53-1be7-47ee-b56b-dd919684acb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['070760', 'png']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['image'].split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "67af1f80-ec80-49eb-b240-6fa559a92ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_all_png(samples):\n",
    "    all_png = [1 for sample in samples if sample['image'].split('.')[-1] == 'png']\n",
    "    return sum(all_png) == len(samples)\n",
    "samples = [\n",
    "    {'image': \"001.png\"},\n",
    "    {'image': \"001.jpg\"}\n",
    "]\n",
    "# samples = random.sample(train_data, 1000)\n",
    "is_all_png(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ca4729c2-92bf-49ad-afe7-11d9faaf9445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = random.sample(train_data, 1000)\n",
    "is_all_png(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c4faf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('L', (1080, 1920))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "depth = Image.open(\"PhysicalAI-Spatial-Intelligence-Warehouse/train_sample/depths/001511_depth.png\")\n",
    "depth.mode, np.asarray(depth).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cbad27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RGB', (1080, 1920, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if depth.mode != 'RGB':\n",
    "    depth_rgb = depth.convert('RGB')\n",
    "depth_rgb.mode, np.asarray(depth_rgb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d2b96a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_rgb.mode != 'RGB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029e936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialrgpt_finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
